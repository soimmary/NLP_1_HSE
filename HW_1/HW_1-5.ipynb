{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–∞–π–ø–ª–∞–π–Ω:**\n",
    "\n",
    "- ‚úÖ –°–Ω–∞—á–∞–ª–∞ –Ω–∞–º –Ω–∞–¥–æ —Å–∫–∞—á–∞—Ç—å –¥–∞—Ç—É ‚Äì —Å–æ–±–µ—Ä–∏—Ç–µ –∫–∞–∫ –º–∏–Ω–∏–º—É–º 60 (30 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ 30 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö) –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã (–Ω–µ –Ω–∞–¥–æ –º–µ—à–∞—Ç—å –æ—Ç–∑—ã–≤—ã –Ω–∞ –æ—Ç–µ–ª–∏ —Å –æ—Ç–∑—ã–≤–∞–º–∏ –Ω–∞ –Ω–æ—É—Ç–±—É–∫–∏) –¥–ª—è —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è \" —Ç–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è\" (—á–µ–º –±–æ–ª—å—à–µ –æ—Ç–∑—ã–≤–æ–≤, —Ç–µ–º –ª—É—á—à–µ) –∏ 10 –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞.\n",
    "\n",
    "\n",
    "- ‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–æ–≤–∞, –ø—Ä–∏–≤–µ–¥–∏—Ç–µ –∏—Ö –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ (1 –±–∞–ª–ª –∑–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é, 1 - –∑–∞ –Ω–∞—á–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É)\n",
    "\n",
    "\n",
    "- ‚úÖ –°–æ—Å—Ç–∞–≤—å—Ç–µ 2 –º–Ω–æ–∂–µ—Å—Ç–≤–∞ - –≤ –æ–¥–Ω–æ–º –±—É–¥—É—Ç —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö, –∞ –≤ –¥—Ä—É–≥–æ–º - –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–ª—å–∫–æ –≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∏–≥—Ä–∞—Ç—å —Å —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—è–º–∏ –∏ –∏—Å–∫–ª—é—á–∏—Ç—å —à—É–º (–∫ –ø—Ä–∏–º–µ—Ä—É, –≤—ã–±—Ä–æ—Å–∏—Ç—å —Å–ª–æ–≤–∞, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è 1-2 —Ä–∞–∑–∞) (3 –±–∞–ª–ª–∞) (–µ—Å–ª–∏ —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª–∏—Å—å –ø—É—Å—Ç—ã–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞, —É–±–µ—Ä–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ –∏–ª–∏ —É–≤–µ–ª–∏—á—å—Ç–µ –≤—ã–±–æ—Ä–∫—É)\n",
    "\n",
    "\n",
    "- ‚úÖ –°–æ–∑–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ª–∏ –æ—Ç–∑—ã–≤ –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –≤ –Ω—ë–º, –∏ –ø–æ—Å—á–∏—Ç–∞–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ accuracy (1 - –∑–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é, 1 - –∑–∞ –ø–æ–¥—Å—á—ë—Ç accuracy)\n",
    "\n",
    "\n",
    "- –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –∫–∞–∫ –º–∏–Ω–∏–º—É–º 2 —Å–ø–æ—Å–æ–±–∞ —É–ª—É—á—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–≥—Ä–∞–º–º—É —Å –ø–æ–º–æ—â—å—é –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫ –Ω–µ–π –ª—é–±—ã—Ö –º—É–ª–µ–∫ - –ø—Ä–æ—Å—Ç–æ —Å–ª–æ–≤–∞–º–∏, –ø–∏—Å–∞—Ç—å —É–ª—É—á—à–∞—é—â–∏–π –∫–æ–¥ –Ω–µ –Ω–∞–¥–æ (1 –±–∞–ª–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚Ññ1 Parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C–æ–±–∏—Ä–∞–µ–º >60 (30 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ 30 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö) –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã  –¥–ª—è —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è \"—Ç–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è\" –∏ 10 –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ë–µ—Ä—ë–º –æ—Ç–∑—ã–≤—ã –Ω–∞ —Ä—è–∑–∞–Ω—Å–∫–∏–µ –æ—Ç–µ–ª–∏ —Å —Å–∞–π—Ç–∞ tripadvisor.ru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "from pymystem3 import Mystem\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "m = Mystem()\n",
    "pymorph = pymorphy2.MorphAnalyzer()\n",
    "punctuation = \"\"\"!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~‚Äì‚Äî¬´¬ª\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefoxdriver_path = '/Users/mariabocharova/PycharmProjects/REALEC/firefoxdriver'\n",
    "chromedriver_path = '/Users/mariabocharova/PycharmProjects/REALEC/chromedriver'\n",
    "\n",
    "hotels = ['https://www.tripadvisor.ru/Hotel_Review-g298485-d1732311-Reviews-Congress_Hotel_Forum-Ryazan_Ryazan_Oblast_Central_Russia.html', \n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g15512259-d6533471-Reviews-Tourist_Base_Polushkino-Polushkino_Ryazan_Oblast_Central_Russia.html', \n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g298485-d7257464-Reviews-Hostel_Like-Ryazan_Ryazan_Oblast_Central_Russia.html', \n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g298485-d10817084-Reviews-Kremlyovskiy-Ryazan_Ryazan_Oblast_Central_Russia.html', \n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g298485-d1469261-Reviews-Aragon_Hotel-Ryazan_Ryazan_Oblast_Central_Russia.html',\n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g298485-d5534355-Reviews-V_Nekotorom_Tsarstve_Hotel-Ryazan_Ryazan_Oblast_Central_Russia.html',\n",
    "          'https://www.tripadvisor.ru/Hotel_Review-g298485-d7133243-Reviews-Hotel_Ryazan-Ryazan_Ryazan_Oblast_Central_Russia.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.DataFrame(columns=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(hotel_link, save_to_path, firefoxdriver_path='/Users/mariabocharova/PycharmProjects/REALEC/firefoxdriver'):\n",
    "    options = Options()\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    driver = webdriver.Firefox(executable_path=firefoxdriver_path)\n",
    "    driver.get(hotel_link)\n",
    "    time.sleep(5)\n",
    "\n",
    "    with open(save_to_path, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        try:\n",
    "            while driver.find_element_by_xpath(\".//a[@class='ui_button nav next primary ']\"):\n",
    "                # –ù–∞—Ö–æ–∂—É –±–ª–æ–∫ —Å –æ—Ü–µ–Ω–∫–æ–π –∏ –æ—Ç–∑—ã–≤–æ–º\n",
    "                reviews = driver.find_elements_by_xpath(\"//div[@data-test-target='HR_CC_CARD']\")\n",
    "                for review in reviews:\n",
    "                    text = review.find_element_by_xpath(\".//q[@class='XllAv H4 _a']\").text\n",
    "                    score = float(review.find_element_by_xpath(\".//span[contains(@class, 'ui_bubble_rating bubble_')]\")\n",
    "                                .get_attribute(\"class\").strip('ui_bubble_rating bubble_'))\n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è—é –æ—Ü–µ–Ω–∫—É –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π\n",
    "                    writer.writerow([score / 10, text])\n",
    "                driver.find_element_by_xpath(\".//a[@class='ui_button nav next primary ']\").click()\n",
    "                time.sleep(7)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tripadvisor_reviews.csv', 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['score', 'text'])\n",
    "for link in tqdm(hotels):\n",
    "    get_reviews(link, 'tripadvisor_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tripadvisor_reviews.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –æ—Ç–∑—ã–≤ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º, –µ—Å–ª–∏ –µ–≥–æ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –Ω–∞ 4-5. –ï—Å–ª–∏ –æ—Ü–µ–Ω–∫–∞ –º–µ–Ω—å—à–µ ‚Äì —Ç–æ –æ—Ç–∑—ã–≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    309\n",
       "4.0    183\n",
       "3.0     72\n",
       "1.0     29\n",
       "2.0     22\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–±–µ—Ä–µ–º —Ä–∞–Ω–¥–æ–º–Ω—ã–µ 120 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ 120 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df.loc[df['score'] >= 4].sample(n = 120)\n",
    "df_negative = df.loc[df['score'] < 4].sample(n = 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–î–æ—Å—Ç–∞–Ω–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.tripadvisor.ru/Hotel_Review-g298485-d6851547-Reviews-Esenin-Ryazan_Ryazan_Oblast_Central_Russia.html'\n",
    "get_reviews(link, 'tripadvisor_reviews_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemm_text = ''\n",
    "    for word in m.lemmatize(text):\n",
    "        if word.isalpha():\n",
    "            lemm_text += f'{word} '\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tripadvisor_reviews_prediction.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    negative_predict = [lemmatize(line[5:-2]).strip() for line in f if float(line[0:3]) < 4][:10]\n",
    "\n",
    "with open('tripadvisor_reviews_prediction.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    positive_predict = [lemmatize(line[5:-2]).strip() for line in f if float(line[0:3]) >= 4][:10]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    34\n",
       "5.0    32\n",
       "3.0    28\n",
       "2.0    11\n",
       "1.0    10\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = pd.read_csv('tripadvisor_reviews_prediction.csv')\n",
    "df_predict['score'].value_counts(sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚Ññ2 –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–≤–∞, –ø—Ä–∏–≤–æ–¥–∏–º –∏—Ö –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive['text_lemm'] = df_positive['text'].apply(lemmatize)\n",
    "df_negative['text_lemm'] = df_negative['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5.0</td>\n",
       "      <td>–û—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å –Ω–∞ 1 –Ω–æ—á—å. –ù–æ–º–µ—Ä —Å–µ–º–µ–π–Ω—ã–π –æ–∫–∞–∑–∞–ª—Å...</td>\n",
       "      <td>–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ –Ω–æ—á—å –Ω–æ–º–µ—Ä —Å–µ–º–µ–π–Ω—ã–π –æ–∫–∞–∑—ã–≤–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4.0</td>\n",
       "      <td>–°—Ä–µ–¥–Ω–∏–π –æ—Ç–µ–ª—å) –±–æ–ª—å—à–æ–π –ø–ª—é—Å - —ç—Ç–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ...</td>\n",
       "      <td>—Å—Ä–µ–¥–Ω–∏–π –æ—Ç–µ–ª—å –±–æ–ª—å—à–æ–π –ø–ª—é—Å —ç—Ç–æ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>4.0</td>\n",
       "      <td>–ù–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥ –ø—Ä–æ—Å—Ç–∞—è –∫–∏—Ä–ø–∏—á–Ω–∞—è –∫–æ—Ä–æ–±–∫–∞ –æ—Ç–µ...</td>\n",
       "      <td>–Ω–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥ –ø—Ä–æ—Å—Ç–æ–π –∫–∏—Ä–ø–∏—á–Ω—ã–π –∫–æ—Ä–æ–±–∫–∞ –æ—Ç–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score                                               text  \\\n",
       "198    5.0  –û—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å –Ω–∞ 1 –Ω–æ—á—å. –ù–æ–º–µ—Ä —Å–µ–º–µ–π–Ω—ã–π –æ–∫–∞–∑–∞–ª—Å...   \n",
       "294    4.0  –°—Ä–µ–¥–Ω–∏–π –æ—Ç–µ–ª—å) –±–æ–ª—å—à–æ–π –ø–ª—é—Å - —ç—Ç–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ...   \n",
       "538    4.0  –ù–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥ –ø—Ä–æ—Å—Ç–∞—è –∫–∏—Ä–ø–∏—á–Ω–∞—è –∫–æ—Ä–æ–±–∫–∞ –æ—Ç–µ...   \n",
       "\n",
       "                                             text_lemm  \n",
       "198  –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ –Ω–æ—á—å –Ω–æ–º–µ—Ä —Å–µ–º–µ–π–Ω—ã–π –æ–∫–∞–∑—ã–≤–∞...  \n",
       "294  —Å—Ä–µ–¥–Ω–∏–π –æ—Ç–µ–ª—å –±–æ–ª—å—à–æ–π –ø–ª—é—Å —ç—Ç–æ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ...  \n",
       "538  –Ω–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥ –ø—Ä–æ—Å—Ç–æ–π –∫–∏—Ä–ø–∏—á–Ω—ã–π –∫–æ—Ä–æ–±–∫–∞ –æ—Ç–µ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚Ññ3 –ú–Ω–æ–∂–µ—Å—Ç–≤–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ—Å—Ç–∞–≤–ª—è–µ–º 2 –º–Ω–æ–∂–µ—Å—Ç–≤–∞ ‚Äì –≤ –æ–¥–Ω–æ–º  —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö, –∞ –≤ –¥—Ä—É–≥–æ–º ‚Äì –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–ª—å–∫–æ –≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sets_of_words(df_positive, df_negative):\n",
    "    positive_reviews = Counter(' '.join(df_positive['text_lemm']).split())\n",
    "    negative_reviews = Counter(' '.join(df_negative['text_lemm']).split())\n",
    "\n",
    "    positive_reviews = set({word: n for word, n in positive_reviews.items() if n > 1})\n",
    "    negative_reviews = set({word: n for word, n in negative_reviews.items() if n > 1})\n",
    "\n",
    "    positive_words_set = positive_reviews - negative_reviews\n",
    "    negative_words_set = negative_reviews - positive_reviews\n",
    "    \n",
    "    return positive_words_set, negative_words_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚Ññ4 –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤ –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏—Å—å –≤ –Ω—ë–º, –∏ —Å—á–∏—Ç–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –ø–æ–º–æ—â–∏ accuracy (1 - –∑–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é, 1 - –∑–∞ –ø–æ–¥—Å—á—ë—Ç accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tone(text, positive_words_set, negative_words_set):\n",
    "    text = lemmatize(text).split()\n",
    "    bigrams = list(nltk.bigrams(text))\n",
    "\n",
    "    positive_unigram_num = len([word for word in text if word in positive_words_set])\n",
    "    negative_unigram_num = len([word for word in text if word in negative_words_set])\n",
    "    \n",
    "    # –î–æ–±–∞–≤–∏–ª–∞ –≤–æ—Ç —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏\n",
    "    positive_bigram_num = len([bigram for bigram in bigrams if ' '.join(bigram) in positive_words_set])\n",
    "    negative_bigram_num = len([bigram for bigram in bigrams if ' '.join(bigram) in negative_words_set])\n",
    "    \n",
    "    positive_percent = round((positive_unigram_num + positive_bigram_num) / len(text) * 100, 2)\n",
    "    negative_percent = round((negative_unigram_num + negative_bigram_num) / len(text) * 100, 2)\n",
    "    \n",
    "    return positive_percent, negative_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°—á–∏—Ç–∞–µ–º accuracy –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of detecting negative reviews: 0.9\n"
     ]
    }
   ],
   "source": [
    "neg_gold = [1] * 10\n",
    "neg_results = []\n",
    "\n",
    "for prediction in negative_predict:\n",
    "    positive_words_set, negative_words_set = make_sets_of_words(df_positive, df_negative)\n",
    "    pos, neg = predict_tone(prediction, positive_words_set, negative_words_set)\n",
    "    if neg > pos:\n",
    "        neg_results.append(1)\n",
    "    else:\n",
    "        neg_results.append(0)\n",
    "print('Accuracy of detecting negative reviews:', accuracy_score(neg_gold, neg_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–°—á–∏—Ç–∞–µ–º accuracy –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of detecting positive reviews: 0.2\n"
     ]
    }
   ],
   "source": [
    "pos_gold = [1] * 10\n",
    "pos_results = []\n",
    "\n",
    "for prediction in positive_predict:\n",
    "    positive_words_set, negative_words_set = create_sets_of_words(df_positive, df_negative)\n",
    "    pos, neg = predict_tone(prediction, positive_words_set, negative_words_set)\n",
    "    if pos > neg:\n",
    "        pos_results.append(1)\n",
    "    else:\n",
    "        pos_results.append(0)\n",
    "print('Accuracy of detecting positive reviews:', accuracy_score(pos_gold, pos_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations, –∏–ª–∏ –∫–∞–∫ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —É–ª—É—á—à–∏—Ç—å "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ—Ç—ã –∏–∑ –±–∏–≥—Ä–∞–º–º, –∞ –Ω–µ –∏–∑ –µ–¥–∏–Ω–∏—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤. –¢–æ–≥–¥–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–µ—Ç—ã —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–∑ –æ—Ç–∑—ã–≤–æ–≤ _–º–Ω–µ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è –æ—Ç–µ–ª—å_ –∏ _–º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è –æ—Ç–µ–ª—å_ –±—É–¥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞–ª–∏—á–∏–µ–º/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º —á–∞—Å—Ç–∏—Ü—ã _–Ω–µ_, –ø–æ –∫–æ—Ç–æ—Ä–æ–π –Ω–µ–ª—å–∑—è –ø–æ–Ω—è—Ç—å, –∫ —á–µ–º—É –æ–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è. \n",
    "2. –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å POS tags –∏ —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–æ–ª—å–∫–æ Noun, Adjective, Adverb, Verb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPD –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–π –¥–æ–º–∞—à–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [i for i in nltk.word_tokenize(text) if i not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_NEG_VERB(tokens):\n",
    "    pattern_matches = []\n",
    "    \n",
    "    for i in range(len(tokens)-1):\n",
    "        current_token = tokens[i].lower()\n",
    "        next_token = tokens[i+1].lower()\n",
    "        if current_token == '–Ω–µ' and pymorph.parse(next_token)[0].tag.POS in ['INFN', 'GRND', 'PRTF', 'PRTS']:\n",
    "            pattern_matches.append((current_token, next_token))\n",
    "    \n",
    "    return pattern_matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_ADV_VERB(tokens):\n",
    "    pattern_matches = []\n",
    "\n",
    "    for i in range(len(tokens)-2):\n",
    "        current_token = tokens[i].lower()\n",
    "        next_token = tokens[i+1].lower()\n",
    "        \n",
    "        current_token_POS = pymorph.parse(current_token)[0].tag.POS\n",
    "        next_token_POS = pymorph.parse(next_token)[0].tag.POS\n",
    "        \n",
    "        if current_token_POS == 'ADVB' and next_token_POS == 'VERB':\n",
    "            pattern_matches.append((current_token, next_token))\n",
    "    return pattern_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_ADJ_NOUN(tokens):\n",
    "    pattern_matches = []\n",
    "\n",
    "    for i in range(len(tokens)-1):\n",
    "        current_token = tokens[i].lower()\n",
    "        next_token = tokens[i+1].lower()\n",
    "        current_token_POS = pymorph.parse(current_token)[0].tag.POS\n",
    "        next_token_POS = pymorph.parse(next_token)[0].tag.POS\n",
    "        if (current_token_POS == 'ADJF' or current_token_POS == 'ADJS') and next_token_POS == 'NOUN':\n",
    "            pattern_matches.append((current_token, next_token))\n",
    "    return pattern_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π:**\n",
    "1. –î–µ–ª–∞—é —Å–µ—Ç—ã –∏–∑ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —É–Ω–∏–≥—Ä–∞–º.\n",
    "2. –î–µ–ª–∞—é —Å–µ—Ç—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω–∞–º. \n",
    "3. –ü—Ä–æ–≤–µ—Ä—è—é —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç:\n",
    "    - –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É—é –∏ —Å—á–∏—Ç–∞—é –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å –¥–≤—É–º—è —Å–µ—Ç–∞–º–∏ —É–Ω–∏–≥—Ä–∞–º–º. \n",
    "    - –¥–µ–ª–∞—é POS-–∞–Ω–∞–ª–∏–∑, –∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º –∏—â—É –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —Å–µ—Ç–∞–º–∏ –±–∏–≥—Ä–∞–º–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. –î–µ–ª–∞—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤ –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω –±–∏–≥—Ä–∞–º–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_texts = ' '.join(df_positive['text'])\n",
    "negative_texts = ' '.join(df_negative['text'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set_of_patterns(texts):\n",
    "    pattern_set = set()\n",
    "    for nv in get_pattern_NEG_VERB(tokenizer(texts)):\n",
    "        nv = [pymorph.parse(nv[0])[0].normal_form, pymorph.parse(nv[1])[0].normal_form]\n",
    "        pattern_set.add(' '.join(nv))\n",
    "\n",
    "    for av in get_pattern_ADV_VERB(tokenizer(texts)):\n",
    "        av = [pymorph.parse(av[0])[0].normal_form, pymorph.parse(av[1])[0].normal_form]\n",
    "        pattern_set.add(' '.join(av))\n",
    "\n",
    "    for an in get_pattern_ADJ_NOUN(tokenizer(texts)):\n",
    "        an = [pymorph.parse(an[0])[0].normal_form, pymorph.parse(an[1])[0].normal_form]\n",
    "        pattern_set.add(' '.join(an))\n",
    "    \n",
    "    return pattern_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_patterns_full_set = make_set_of_patterns(positive_texts)\n",
    "negative_patterns_full_set = make_set_of_patterns(negative_texts)\n",
    "\n",
    "positive_patterns_set = positive_patterns_full_set - negative_patterns_full_set\n",
    "negative_patterns_set = negative_patterns_full_set - positive_patterns_full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_full_set = positive_words_set | positive_patterns_set\n",
    "negative_full_set = negative_words_set | negative_patterns_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of detecting negative reviews: 0.9\n"
     ]
    }
   ],
   "source": [
    "neg_score = 0\n",
    "for prediction in negative_predict:\n",
    "    pos, neg = predict_tone(prediction, positive_full_set, negative_full_set)\n",
    "    if neg > pos:\n",
    "        neg_score += 1\n",
    "\n",
    "print('Accuracy of detecting negative reviews:', neg_score / len(negative_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of detecting positive reviews: 0.4\n"
     ]
    }
   ],
   "source": [
    "pos_score = 0\n",
    "for prediction in positive_predict:\n",
    "    pos, neg = predict_tone(prediction, positive_full_set, negative_full_set)\n",
    "    if pos > neg:\n",
    "        pos_score += 1\n",
    "print('Accuracy of detecting positive reviews:', pos_score / len(positive_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò—Ç–æ–≥: —É–≤–µ–ª–∏—á–∏–ª–æ—Å—å accuracy of detecting positive reviews: 0.4 üåü!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
